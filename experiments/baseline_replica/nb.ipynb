{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from torchvision.ops import FeaturePyramidNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "\n",
    "from scipy.stats import pearsonr as corr\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "lr = 0.0001\n",
    "batch_size = 300\n",
    "l2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset sample names...\n",
      "Training images: 9841\n",
      "Test images: 159\n",
      "\n",
      "LH training fMRI data shape:\n",
      "(9841, 19004)\n",
      "(Training stimulus images × LH vertices)\n",
      "\n",
      "RH training fMRI data shape:\n",
      "(9841, 20544)\n",
      "(Training stimulus images × RH vertices)\n"
     ]
    }
   ],
   "source": [
    "data = Dataset('../../data/subj01')\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(data, [0.8, 0.2])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet')\n",
    "alexnet.to(device) # send the alexnet to the chosen device ('cpu' or 'cuda')\n",
    "alexnet.eval() # set the alexnet to evaluation mode, since you are not training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layer = \"features.2\" #@param [\"features.2\", \"features.5\", \"features.7\", \"features.9\", \"features.12\", \"classifier.2\", \"classifier.5\", \"classifier.6\"] {allow-input: true}\n",
    "feature_extractor = create_feature_extractor(alexnet, return_nodes=[model_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lf_fmri = []\n",
    "\n",
    "def fit_pca(feature_extractor, dataloader):\n",
    "    # Define PCA parameters\n",
    "    pca = IncrementalPCA(n_components=100, batch_size=batch_size)\n",
    "\n",
    "    # Fit PCA to batch\n",
    "    for _, d in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        if _ == len(dataloader)-1:\n",
    "            break\n",
    "        #lh_fmri += [d[1]]\n",
    "        # Extract features\n",
    "        ft = feature_extractor(d[0].to(device))\n",
    "        # Flatten the features\n",
    "        ft = torch.hstack([torch.flatten(l, start_dim=1) for l in ft.values()])\n",
    "        # Fit PCA to batch\n",
    "        pca.partial_fit(ft.detach().cpu().numpy())\n",
    "\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 26/27 [02:51<00:06,  6.58s/it]\n"
     ]
    }
   ],
   "source": [
    "pca = fit_pca(feature_extractor, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(feature_extractor, dataloader, pca):\n",
    "    lh_fmri = []\n",
    "    features = []\n",
    "    for _, d in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        if _ == len(dataloader)-1:\n",
    "            break\n",
    "        # Extract features\n",
    "        ft = feature_extractor(d[0].to(device))\n",
    "        lh_fmri += [d[1].cpu().detach().numpy()]\n",
    "        # Flatten the features\n",
    "        ft = torch.hstack([torch.flatten(l, start_dim=1) for l in ft.values()])\n",
    "        # Apply PCA transform\n",
    "        ft = pca.transform(ft.cpu().detach().numpy())\n",
    "        features += [ft]\n",
    "    return (np.vstack(features), np.vstack(lh_fmri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 26/27 [01:18<00:03,  3.01s/it]\n",
      " 86%|████████▌ | 6/7 [00:21<00:03,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "features_train, labels_train = extract_features(feature_extractor, train_loader, pca)\n",
    "features_val, labels_val = extract_features(feature_extractor, val_loader, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lh = LinearRegression().fit(features_train, labels_train)\n",
    "lh_fmri_val_pred = reg_lh.predict(features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19004/19004 [00:01<00:00, 10330.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.263217314225553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr as corr\n",
    "\n",
    "# Empty correlation array of shape: (LH vertices)\n",
    "lh_correlation = np.zeros(lh_fmri_val_pred.shape[1])\n",
    "# Correlate each predicted LH vertex with the corresponding ground truth vertex\n",
    "for v in tqdm(range(lh_fmri_val_pred.shape[1])):\n",
    "    lh_correlation[v] = corr(lh_fmri_val_pred[:,v], labels_val[:,v])[0]\n",
    "\n",
    "score = np.median(lh_correlation) * 100\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algonauts",
   "language": "python",
   "name": "algonauts"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
