{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowest val loss: 0.022405 after 3 epochs\n",
    "\n",
    "Lowest train loss: 0.02135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from torchvision.ops import FeaturePyramidNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "from utils.model import RegressionHead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "lr = 2e-3\n",
    "batch_size = 32\n",
    "l2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset + creating train test split for verifying performance\n",
    "dataset = Dataset(\"../../data/subj01\")\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [9000, 841])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor + trainable regression head instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained model\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "layer_names = []\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer_names += [name]\n",
    "\n",
    "print(layer_names)\n",
    "\n",
    "feature_extractor = create_feature_extractor(model, \n",
    "        return_nodes=[\"layer1.1.conv1\", \"layer2.0.conv1\", \"layer3.0.conv1\", \"layer4.0.conv1\"]).to(device)\n",
    "fpn = FeaturePyramidNetwork([64, 128, 256, 512], 256).to(device)\n",
    "\n",
    "\n",
    "# instantiating trainable head\n",
    "head = RegressionHead().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating loss function + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to make spread more closely match target distribution\n",
    "def squared_spread_loss():\n",
    "    def loss(output, target):\n",
    "        output_std = torch.std(output)\n",
    "        target_std = torch.std(target)\n",
    "        return (output_std - target_std) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_weight = 0.5\n",
    "spread_weight = 0.5\n",
    "\n",
    "criterion = nn.MSELoss() # loss\n",
    "auxiliary_spread_loss = squared_spread_loss() # aucilliary loss\n",
    "optimizer = torch.optim.Adam(head.parameters(), lr=lr, weight_decay=l2) # optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting ROI vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 0 #@param\n",
    "hemisphere = 'left' #@param ['left', 'right'] {allow-input: true}\n",
    "roi = \"EBA\" #@param [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\", \"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\", \"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\", \"OPA\", \"PPA\", \"RSC\", \"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\", \"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"] {allow-input: true}\n",
    "\n",
    "\n",
    "# pulling sample\n",
    "sample = next(iter(val_loader))\n",
    "\n",
    "# Define the ROI class based on the selected ROI\n",
    "if roi in [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\"]:\n",
    "    roi_class = 'prf-visualrois'\n",
    "elif roi in [\"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\"]:\n",
    "    roi_class = 'floc-bodies'\n",
    "elif roi in [\"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\"]:\n",
    "    roi_class = 'floc-faces'\n",
    "elif roi in [\"OPA\", \"PPA\", \"RSC\"]:\n",
    "    roi_class = 'floc-places'\n",
    "elif roi in [\"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\"]:\n",
    "    roi_class = 'floc-words'\n",
    "elif roi in [\"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"]:\n",
    "    roi_class = 'streams'\n",
    "\n",
    "# Load the ROI brain surface maps\n",
    "challenge_roi_class_dir = os.path.join(\"../../data/subj01/\", 'roi_masks',\n",
    "    hemisphere[0]+'h.'+roi_class+'_challenge_space.npy')\n",
    "fsaverage_roi_class_dir = os.path.join(\"../../data/subj01/\", 'roi_masks',\n",
    "    hemisphere[0]+'h.'+roi_class+'_fsaverage_space.npy')\n",
    "roi_map_dir = os.path.join(\"../../data/subj01/\", 'roi_masks',\n",
    "    'mapping_'+roi_class+'.npy')\n",
    "challenge_roi_class = np.load(challenge_roi_class_dir)\n",
    "fsaverage_roi_class = np.load(fsaverage_roi_class_dir)\n",
    "roi_map = np.load(roi_map_dir, allow_pickle=True).item()\n",
    "\n",
    "# Select the vertices corresponding to the ROI of interest\n",
    "roi_mapping = list(roi_map.keys())[list(roi_map.values()).index(roi)]\n",
    "challenge_roi = np.asarray(challenge_roi_class == roi_mapping, dtype=int)\n",
    "fsaverage_roi = np.asarray(fsaverage_roi_class == roi_mapping, dtype=int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "mse_train_loss = 0\n",
    "val_loss = 0\n",
    "mse_val_loss = 0\n",
    "count = 0\n",
    "\n",
    "all_train_loss_vals = []\n",
    "all_val_loss_vals = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(\"\\nEpoch \" + str(epoch))\n",
    "\n",
    "    # setting to train mode for gradient calculations\n",
    "    head.train()\n",
    "\n",
    "    for i, (inputs, targets) in tqdm(enumerate(train_loader), total=int(9000/batch_size)+1):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)[:, np.where(challenge_roi)[0]] # selecting proper vertices based on ROI\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # feature extractor backbone\n",
    "        outputs = feature_extractor(inputs)\n",
    "        outputs = fpn(outputs)\n",
    "\n",
    "        # trainable head\n",
    "        outputs = head(outputs)\n",
    "\n",
    "        mse_loss = (mse_weight * criterion(outputs, targets))\n",
    "        loss = mse_loss # + (spread_weight * auxiliary_spread_loss(outputs, targets))\n",
    "        loss.backward()\n",
    "\n",
    "        del inputs\n",
    "        del targets\n",
    "\n",
    "        #mse_train_loss = mse_train_loss + mse_loss.item()\n",
    "        train_loss = train_loss + loss.item()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    torch.cuda.empty_cache() # frees up memory for val\n",
    "\n",
    "    all_train_loss_vals += [train_loss/count]\n",
    "    \n",
    "    print(\"Train loss: \" + str(train_loss/count))\n",
    "    #print(\"MSE train loss: \" + str(mse_train_loss/count))\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    head.eval()\n",
    "    \n",
    "    for i, (inputs, targets) in tqdm(enumerate(val_loader), total=int(841/batch_size)+1):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)[:, np.where(challenge_roi)[0]] # selecting proper vertices based on ROI\n",
    "\n",
    "        # feature extractor backbone\n",
    "        outputs = feature_extractor(inputs)\n",
    "        outputs = fpn(outputs)\n",
    "\n",
    "        # trainable head\n",
    "        outputs = head(outputs)\n",
    "\n",
    "        mse_loss = (mse_weight * criterion(outputs, targets))\n",
    "        loss = mse_loss #+ (spread_weight * auxiliary_spread_loss(outputs, targets))\n",
    "\n",
    "        del inputs\n",
    "        del targets\n",
    "\n",
    "        #mse_val_loss = mse_val_loss + mse_loss.item()\n",
    "        val_loss = val_loss + loss.item()\n",
    "        count += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    all_val_loss_vals += [val_loss/count]\n",
    "    \n",
    "    print(\"Val loss: \" + str(val_loss/count))\n",
    "    # print(\"MSE val loss: \" + str(mse_val_loss/count))\n",
    "\n",
    "    train_loss = 0\n",
    "    mse_train_loss = 0\n",
    "    val_loss = 0\n",
    "    mse_val_loss = 0\n",
    "    \n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(EPOCHS)], all_train_loss_vals, label=\"Train\")\n",
    "plt.plot([i for i in range(EPOCHS)], all_val_loss_vals, label=\"Val\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"./loss_graphs/5_epochs_roi_EBA.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(head.state_dict(), \"saved_models/5_epochs_roi_EBA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### original visualization script pulled from challenge provided notebook\n",
    "\n",
    "# pulling sample\n",
    "sample = next(iter(val_loader))\n",
    "\n",
    "# Map the truth fMRI data onto the brain surface map\n",
    "fsaverage_response_truth = np.zeros(len(fsaverage_roi))\n",
    "if hemisphere == 'left':\n",
    "    fsaverage_response_truth[np.where(fsaverage_roi)[0]] = \\\n",
    "        sample[1][0][np.where(challenge_roi)[0]]\n",
    "elif hemisphere == 'right':\n",
    "    fsaverage_response_truth[np.where(fsaverage_roi)[0]] = \\\n",
    "        sample[1][0][np.where(challenge_roi)[0]]\n",
    "\n",
    "# Map the predicted fMRI data onto the brain surface map\n",
    "feature_extractor.to(\"cpu\")\n",
    "fpn.to(\"cpu\")\n",
    "head.to(\"cpu\")\n",
    "\n",
    "visualize_output = feature_extractor(sample[0])\n",
    "visualize_output = fpn(visualize_output)\n",
    "visualize_output = head(visualize_output).detach()\n",
    "\n",
    "fsaverage_response_predicted = np.zeros(len(fsaverage_roi))\n",
    "if hemisphere == 'left':\n",
    "    fsaverage_response_predicted[np.where(fsaverage_roi)[0]] = \\\n",
    "        visualize_output[0]\n",
    "elif hemisphere == 'right':\n",
    "    fsaverage_response_predicted[np.where(fsaverage_roi)[0]] = \\\n",
    "        visualize_output[0]\n",
    "\n",
    "# Create the interactive brain surface map\n",
    "fsaverage = datasets.fetch_surf_fsaverage('fsaverage')\n",
    "view1 = plotting.view_surf(\n",
    "    surf_mesh=fsaverage['infl_'+hemisphere],\n",
    "    surf_map=fsaverage_response_truth,\n",
    "    bg_map=fsaverage['sulc_'+hemisphere],\n",
    "    threshold=1e-14,\n",
    "    cmap='cold_hot',\n",
    "    colorbar=True,\n",
    "    title=roi+', '+hemisphere+' hemisphere')\n",
    "\n",
    "view2 = plotting.view_surf(\n",
    "    surf_mesh=fsaverage['infl_'+hemisphere],\n",
    "    surf_map=fsaverage_response_predicted,\n",
    "    bg_map=fsaverage['sulc_'+hemisphere],\n",
    "    threshold=1e-14,\n",
    "    cmap='cold_hot',\n",
    "    colorbar=True,\n",
    "    title=roi+', '+hemisphere+' hemisphere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(val_loader))\n",
    "print(\"Output dims: \" + str(visualize_output[0].size()))\n",
    "print(\"Target dims: \" + str(sample[1][0][np.where(challenge_roi)[0]].size()))\n",
    "\n",
    "print(\"Output mean: \" + str(torch.mean(visualize_output[0]) ** 2))\n",
    "print(\"Target mean: \" + str(torch.mean(sample[1][0][np.where(challenge_roi)[0]]) ** 2))\n",
    "\n",
    "loss = criterion(visualize_output[0], sample[1][0][np.where(challenge_roi)[0]])\n",
    "\n",
    "print(\"Loss: \" + str(loss))\n",
    "\n",
    "plt.hist(sample[1][0][np.where(challenge_roi)[0]].numpy(), bins=100, label=\"target\")\n",
    "plt.hist(visualize_output[0].numpy(), bins=100, label=\"model output\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(\"histograms/\" + \"5_epochs_roi_EBA\" + \".output.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
