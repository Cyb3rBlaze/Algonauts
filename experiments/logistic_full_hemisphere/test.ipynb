{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from torchvision.ops import FeaturePyramidNetwork\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr as corr\n",
    "\n",
    "from utils.dataset_test import Dataset\n",
    "from utils.dataset import ReferenceDataset\n",
    "from utils.model import RegressionHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = \"right\"\n",
    "hemisphere = \"rh\"\n",
    "subject = \"subj01\"\n",
    "batch_size = 159\n",
    "vertex_count = 20544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset sample names...\n",
      "Test images: 159\n",
      "Loading dataset sample names...\n",
      "Training images: 9841\n",
      "Test images: 159\n"
     ]
    }
   ],
   "source": [
    "# loading dataset + creating train test split for verifying performance\n",
    "dataset = Dataset(\"../../data/\" + subject)\n",
    "reference_dataset = ReferenceDataset(\"../../data/\" + subject, side=hemisphere)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "reference_loader = torch.utils.data.DataLoader(reference_dataset, batch_size=32, shuffle=False)\n",
    "stats = reference_dataset.getStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor + trainable regression head instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'layer1.0.conv1', 'layer1.0.conv2', 'layer1.0.conv3', 'layer1.0.downsample.0', 'layer1.1.conv1', 'layer1.1.conv2', 'layer1.1.conv3', 'layer1.2.conv1', 'layer1.2.conv2', 'layer1.2.conv3', 'layer2.0.conv1', 'layer2.0.conv2', 'layer2.0.conv3', 'layer2.0.downsample.0', 'layer2.1.conv1', 'layer2.1.conv2', 'layer2.1.conv3', 'layer2.2.conv1', 'layer2.2.conv2', 'layer2.2.conv3', 'layer2.3.conv1', 'layer2.3.conv2', 'layer2.3.conv3', 'layer3.0.conv1', 'layer3.0.conv2', 'layer3.0.conv3', 'layer3.0.downsample.0', 'layer3.1.conv1', 'layer3.1.conv2', 'layer3.1.conv3', 'layer3.2.conv1', 'layer3.2.conv2', 'layer3.2.conv3', 'layer3.3.conv1', 'layer3.3.conv2', 'layer3.3.conv3', 'layer3.4.conv1', 'layer3.4.conv2', 'layer3.4.conv3', 'layer3.5.conv1', 'layer3.5.conv2', 'layer3.5.conv3', 'layer4.0.conv1', 'layer4.0.conv2', 'layer4.0.conv3', 'layer4.0.downsample.0', 'layer4.1.conv1', 'layer4.1.conv2', 'layer4.1.conv3', 'layer4.2.conv1', 'layer4.2.conv2', 'layer4.2.conv3']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressionHead(\n",
       "  (poolx2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsamplex2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final_conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bnorm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final_conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bnorm6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final_conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bnorm7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final_conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bnorm8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (aggregate): AvgPool2d(kernel_size=(18, 18), stride=(18, 18), padding=0)\n",
       "  (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (dense2): Linear(in_features=1024, out_features=20544, bias=True)\n",
       "  (gelu): GELU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "layer_names = []\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer_names += [name]\n",
    "\n",
    "print(layer_names)\n",
    "\n",
    "feature_extractor = create_feature_extractor(model, \n",
    "        return_nodes=[\"layer1.1.conv1\", \"layer2.0.conv1\", \"layer3.0.conv1\", \"layer4.0.conv1\"]).to(device)\n",
    "fpn = FeaturePyramidNetwork([64, 128, 256, 512], 256).to(device)\n",
    "\n",
    "feature_extractor.eval()\n",
    "\n",
    "\n",
    "# instantiating trainable head\n",
    "head = RegressionHead(vertex_count).to(device)\n",
    "head.load_state_dict(torch.load(\"saved_models/5_epochs_aux_\" + subject + \"_\" + side))\n",
    "head.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)\n",
    "with torch.no_grad():\n",
    "    for i, (image, label) in enumerate(reference_loader):\n",
    "        if(i > 0):\n",
    "            break\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        outputs = feature_extractor(image)\n",
    "        outputs = fpn(outputs)\n",
    "        outputs = head(outputs)\n",
    "\n",
    "        loss = nn.MSELoss()\n",
    "        print(loss(outputs, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
