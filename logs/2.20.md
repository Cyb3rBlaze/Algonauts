Picked up some really interesting insights today and understand the data + the current model's capacity more now. Ran some tests on the output data distribution and strangely, the activations strongly resemble a unit normal distribution (with slight variations in mean and spread).

After 100 epochs of training with the intent to overfit, the loss convergence process slowed down significantly. Loss might continue to trickle down but we expected the model to converge a lot faster. We target model overfitting to force train loss below 0.1 after 40-50 epochs max.

Visualized model output distribution before training and after overfitting -> untrained outputs also resemble normal (with differences in spread) which was expected due to weight intialization + use of batch normalization and its param values.

MSE does make output activation distribution resemble the target activation distribution (the spread of the targets does increase) but the spreading effect is limited and even after 100 epochs, the distribution is not nearly as spread as it should be.

Even after testing without GELU activations to see if compouneded semi-sparse computations could possibly contribute, the results were pretty much the same.

I hypothesize that this is due to the lack of representational capacity present within the model to quickly adapt + overfit on the training data output distribution. I think that this issue can be cured with a few potential paths:
- Utilizing a nonlinear activation function and turn this linear regression problem into a logistic regression problem. In order for us to do this we will need to normalize target outputs + model outputs to be squashed within a value range. Additionally, we will also need to normalize inputs to the final activation (to resemble unit distribution with mean 0) to ensure that the nonlinear activation outputs aren't super polarized -> treat this like an image generation problem with pixel-wise predictions between -1 and 1.
- Using an auxiliary loss function in addition to MSE to weigh the spread matching effect higher.
- Increase model size + representational capacity (last resort).

Update!
- Tested spread loss and it reduced both train and validation loss significantly (including just MSE) so theory on output distribution mismatch was correct
- The goal is to reduce weightage given to spread loss as much as possible while maintaining target distribution spread characteristics
- Will now begin to introduce regularization to improve model validation performance
- Removed bias for layers before batch norm to prevent unnecessary computations

TODO:
- Test out logistic regression performance - normalize outputs, use tanh activation, and batch norm right before final activation
- Test out doubled learning rate + convergence capabilities and speed
- Try increasing spread loss weightage to make val output distribution match target output distribution closely
- Test model representational capacity so it overfits very fast (increase by a few trainable layers and analyze impact)
- Make sure validation spread and train spread match really well
- Test performance on outputting all activations at once instead of a single ROI
- Prevent neuron misfiring due to overfitting with regularization
- IMPORTANT: throughout each intermediate experiment, analyze correlation score which is used as ranking metric for challenge